# 爬取水深之處各類標題_分類寫檔

實作日期:2021/05/20

## 實作1
```python
def myTest(subject):
  web_Url = requests.get("http://www.luke54.org/index.php?option=com_jumi&view=application&fileid=41&cat=" + subject) 
  # 將此水深之處頁面的 HTML碼 抓取出來

  soup = BeautifulSoup(web_Url.text,"html.parser") 
  # 將網頁資料以 html.parser 來解析

  sel = soup.select("div.item-title a") 
  # 抓取HTML標籤中的 <div class="item-title"></div> 中的<a>標籤存入變數sel裡

  result = [] 
  # 用來儲存爬取的Data 的 Array
  for title_string in sel:
    result.append((title_string.text, title_string["href"]))
    # 將爬取的頁面標題 And 網址,依序加入 result Array
    
  print("-----------------------------------") # 分隔線
  
  df = pd.DataFrame(result, columns=["標題", "網址"])
  df.to_csv(subject + "_web_titile" + '.csv',encoding ='utf-8-sig')
  # 寫檔,並分類各自儲存成一個 csv檔
  
  print("")

delay_choices = [1, 3, 5, 7]  #延遲的秒數
delay = random.choice(delay_choices)  #隨機選取秒數
# 目的: 降低網頁爬蟲被偵測封鎖的機率

print("顯示主題為_真理_的最新文章標題:")
myTest("truth")
time.sleep(delay) # 隨機延遲個幾秒

print("顯示主題為_見證_的最新文章標題:")
myTest("testimony")

print("顯示主題為_時事_的最新文章標題:")
myTest("current")
time.sleep(delay) # 隨機延遲個幾秒

print("顯示主題為_詩歌_的最新文章標題:")
myTest("hymns")
time.sleep(delay) # 隨機延遲個幾秒

print("顯示主題為_影片_的最新文章標題:")
myTest("video")
time.sleep(delay) # 隨機延遲個幾秒

```

## 執行結果

